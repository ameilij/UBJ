\section{Modelos Ensamblados}
El tema de modelos ensamblados es uno que por lo general se reserva más como técnica de composición que cómo teoría del aprendizaje automatizado. Los modelos ensamblados ayudan a mejorar los resultados del aprendizaje automatizado combinando diferentes modelos. Este enfoque permite la producción de mejores modelos predictivos en contraposición a la utilización de un solo modelo \cite{smolyakov}.

\subsection{Introducción}
  El uso de modelos ensamblados es en cierta forma la prueba final de la hipótesis de trabajo: la utilización de dos modelos entrecruzados cuyos resultados conforman una tabla temporal de valores esperados de los cuales se genera un nuevo modelo sintético de predicción más general y con mayor capacidad de predicción en juegos de datos de validación cruzada. Este concepto es novel; Witten y Frank lo describen como combinación de métodos múltiples, y escriben: “… un enfoque obvio para hacer mejores decisiones es tomar el resultado de diferentes métodos y combinarlos\ldots” \cite{datamining}. Zhou nos describe que “… los modelos ensamblados que entrenan múltiples variables y luego las combinan para uso de entrenamiento, con el Boosting y el Bagging como representantes principales, representan lo más novedoso en el estado del arte de la ciencia de datos…” \cite[p. 7]{ensembleMethods}. De una manera un tanto más coloquial, Zhang y Ma describen el uso de modelos ensamblados con una analogía de la vida real, en la cual los pacientes buscan una segunda y hasta tercera opinión de expertos antes de someterse a una operación complicada \cite{ensembleMachineLearning}. Curiosamente tanto Zhang, Ma y Zhou hablan de la combinación de métodos de regresión general con clasificadores, y solo Witten y Frank hablan de otras combinaciones (por supuesto, Witten y Frank comenzaban a escribir en los albores del ensamblaje de métodos, cuando los clasificadores no estaban tan de moda porque el análisis era mayoritariamente de números, algo que cambió con el avance de las redes sociales). Una de las descripciones más sucintas y prácticas es la de Vadim Smolyakov, quien define el uso de modelos ensamblados como meta-algoritmos que combinan dos o más técnicas de aprendizaje automatizado en un modelo predictivo de forma que se logre disminuir la varianza (bagging), el sesgo (boosting) o se mejore la precisión (stacking) \cite{smolyakov}.

\subsection{Combinando Métodos}
La combinación de métodos es el ultimo paso en la estrategia de construcción de un sistema ensamblado de aprendizaje automatizado. La pregunta de que métodos combinar esta estrechamente relacionado con el tipo de juegos de datos y la solución que se busca alcanzar. Por ejemplo, alguno métodos de clasificación como los vectores de soporte solo devuelven valores discretos \cite{ensembleMachineLearning}. De tal manera el uso de dos métodos alternos en uno ensamblado estará determinado por la forma final en que se ensamblan y el algoritmo final utilizado para la decisión de predicción. Tanto Polikar \cite{ensembleMachineLearning} como Zhou \cite{ensembleMethods} citan como preferibles las metodologías de voto por mayoría, promedio, promedio ponderado, y ensamblaje infinito.

Smolyakov divide los métodos ensamblados en dos grandes clasificaciones \cite{smolyakov}:

\begin{itemize}
  \item \textbf{Métodos Ensamblados Secuenciales:} son aquellos donde los modelos bases de aprendizaje se generan de forma secuencial. La idea inicial es que se explota la dependencia entre dichos modelos base al momento de generarlos. Un buen ejemplo de modelos ensamblados secuenciales es \emph{AdaBoost}. El desempeño de predicción o la acotación del margen de error se optimiza al calibrar los regresores y/o clasificadores después de cada entrenamiento y previo al próximo.
  \item \textbf{Métodos Ensamblados Paralelos:} son aquellos en los cuales los modelos bases se generar en forma paralela e independiente. Un buen ejemplo de modelos ensamblados paralelos es \emph{Random Forest}. La motivación de utilizar modelos ensamblados paralelos es maximizar la independencia entre los regresores y/o clasificadores que se optimizan entre si al promediar los resultados, reduciendo el margen de error.
\end{itemize}


\subsection{Diversidad}
La diversidad de ensamblaje, o la diferencia entre diferentes métodos de aprendizaje, es un tema fundamental en el ensamblaje de métodos \cite{ensembleMethods}. Intuitivamente es fácil entender que para obtener una ventaja de la combinación, es necesario que los aprendizajes sean diferentes, de otra manera la ganancia en desempeño no seria marginalmente superior a los métodos por separado \cite{ensembleMethods}.

La mayoría de los métodos ensamblados utilizan solo un tipo de modelo base de algoritmo de aprendizaje para producir regresores o clasificadores homogéneos (del mismo tipo) conocidos como \textit{ensamblajes homogéneos} \cite{smolyakov}. También existen métodos que utilizan diferentes tipos de modelos bases como clasificadores y/o regresores. Estos modelos ensamblados se conocen como \textit{modelos heterogeneos}. Para poder ensamblar modelos más precisos que cualquiera de sus modelos base por si solos es necesario que los modelos bases sean precisos en primera instancia, y tan diversos como sea matemáticamente posible \cite{smolyakov}.

Para propósitos de este marco teórico revisaremos de forma breve los tres métodos más utilizados en la actualidad para el ensamblaje que son:
\begin{itemize}
  \item Bagging: cuando se busca reducir la varianza en los clasificadores
  \item Boosting: cuando se busca reducir el sesgo
  \item Stacking: cuando se busca aumentar la predicción de los regresores
\end{itemize}

Dado que la hipótesis de trabajo del siguiente estudio utiliza el ensamblaje heterogéneo de modelos bases de regresión lineal y pronóstico de series de tiempo con ARIMA, haremos un alto para entrar con más detalle en la teoría y bondades de los modelos apilados (\emph{stacking}).

\subsection{Bagging}
La idea del \emph{bagging} esta estrechamente ligada al \emph{bootstrapping}, y determinada por la selección de múltiples muestras de datos generadas a través de \emph{bootstrapping}, utilizadas para alimentar clasificadores, sobre cuyos resultados el método ensamblado puede votar \cite{daume}. La palabra \emph{bagging} es la composición de \emph{bootstrap aggregation}. La etimología proviene de la metodología propia del método, que usa la agregación de múltiples muestras generadas de los datos disponibles (por ende, el \emph{bootstrapping}) para promediar múltiples estimados \cite{smolyakov}.
Por ejemplo, se pudiera utilizar el \emph{bagging} para entrenar M árboles diferentes en diferentes juegos de datos seleccionados al azar con reemplazo para computar el ensamblado siguiente:

\[ f(x) = \frac{1}{M} \sum_{m=1}^M f_m^{(x)} \]

\emph{Bagging} utiliza muestreo por \emph{bootstrap} para obtener juegos de datos para entrenar los modelos base. Para agregar los resultados de los modelos base, el \emph{bagging} utiliza dos maneras:
\begin{enumerate}
  \item votación para clasificadores
  \item promedios para regresión
\end{enumerate}

\subsection{Boosting}
El \emph{boosting} se refiere a una familia de técnicas de algoritmos que tienen la capacidad de convertir clasificadores (o regresores) débiles en entrenadores fuertes. El principio del \emph{boosting} es calzar una secuencia de clasificadores débiles - modelos que son escasamente mejores en la predicción que selección al azar, como por ejemplo pequeños árboles de decisión - a versiones ajustadas y sopesadas de los datos. Más peso se le otorga a los clasificadores que fueron mal clasificados en rondas anteriores \cite{smolyakov}. Daume describe el método como "\ldots La forma en la cual funciona el \emph{boosting} es que basado en un juego de datos y resultados pasados, va generando nuevas predicciones. Las predicciones con resultados aceptables se les pone menor peso y recursos, mientras que el algoritmo vuelve a iterar en aquellas predicciones con valores lejanos hasta que cobran fuerza \ldots" \cite{daume}. Esta técnica recibe el nombre de \textbf{AdaBoost}, del ingles \emph{adaptive boosting algotithm}. \textbf{AdaBoost} fue una de las primeras técnicas practicas en la ciencia de datos.

Los algoritmos de \emph{AdaBoost} comienzan ajustando los pesos del clasificador base \(y_1(x)\) a \(\frac{1}{N}\). Al comienzo todos los coeficientes de peso son los mismos. En rondas subsiguientes los coeficientes de peso se aumentan para aquellos puntos de datos que han sido mal clasificados y se reduce el peso de aquellos que han sido clasificados correctamente. Esta iteración es la que permite fortalecer los clasificadores débiles (a la vez fortaleciendo los débiles y debilitando los fuertes para contrastar mejor) \cite{smolyakov}.

Existe una variable epsilon que representa el error ajustado de cada clasificador base. Hacia el final de las iteraciones del algoritmo los coeficientes ajustados alfa le otorgan mayor peso a los clasificadores con mayor precisión (la cual ha sido ajustada en \(n\) iteraciones).

Una metodología derivada es el \emph{Boosting de Árboles Degradados}. Dicho método es una generalización del \emph{boosting} para funciones arbitrarias de pérdida \cite{smolyakov}. El mismo se puede utilizar tanto para problemas de clasificación como de regresión, y construye el modelo de forma secuencial:

\[ F_m(x) = F_{m-1}(x) + \gamma_m^{h_m(x)} \]

En cada nodo del árbol de decisión \(h_m(x)\) se elige para minimizar una función de pérdida \(L\) dado el modelo actual \(F_{m-1}(x)\):

\[ F_m(x) = F_{m-1}(x) + \argmin_h \sum_{i=1}^n L(y_i, F_{m-1}(x_i) + h(x_i) )\]

Los algoritmos para regresión y clasificación en este caso utilizan diferentes tipos de funciones de pérdida cuya explicación queda fuera del alcance de este marco teórico.
