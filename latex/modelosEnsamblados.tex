\section{Modelos Ensamblados}
El tema de modelos ensamblados es uno que por lo general se reserva más como técnica de composición que cómo teoría del aprendizaje automatizado. Los modelos ensamblados ayudan a mejorar los resultados del aprendizaje automatizado combinando diferentes modelos. Este enfoque permite la producción de mejores modelos predictivos en contraposición a la utilización de un solo modelo \cite{smolyakov}.

\subsection{Introducción}
  El uso de modelos ensamblados es en cierta forma la prueba final de la hipótesis de trabajo: la utilización de dos modelos entrecruzados cuyos resultados conforman una tabla temporal de valores esperados de los cuales se genera un nuevo modelo sintético de predicción más general y con mayor capacidad de predicción en juegos de datos de validación cruzada. Este concepto es novel; Witten y Frank lo describen como combinación de métodos múltiples, y escriben: “… un enfoque obvio para hacer mejores decisiones es tomar el resultado de diferentes métodos y combinarlos\ldots” \cite{datamining}. Zhou nos describe que “… los modelos ensamblados que entrenan múltiples variables y luego las combinan para uso de entrenamiento, con el Boosting y el Bagging como representantes principales, representan lo más novedoso en el estado del arte de la ciencia de datos…” \cite[p. 7]{ensembleMethods}. De una manera un tanto más coloquial, Zhang y Ma describen el uso de modelos ensamblados con una analogía de la vida real, en la cual los pacientes buscan una segunda y hasta tercera opinión de expertos antes de someterse a una operación complicada \cite{ensembleMachineLearning}. Curiosamente tanto Zhang, Ma y Zhou hablan de la combinación de métodos de regresión general con clasificadores, y solo Witten y Frank hablan de otras combinaciones (por supuesto, Witten y Frank comenzaban a escribir en los albores del ensamblaje de métodos, cuando los clasificadores no estaban tan de moda porque el análisis era mayoritariamente de números, algo que cambió con el avance de las redes sociales). Una de las descripciones más sucintas y prácticas es la de Vadim Smolyakov, quien define el uso de modelos ensamblados como meta-algoritmos que combinan dos o más técnicas de aprendizaje automatizado en un modelo predictivo de forma que se logre disminuir la varianza (bagging), el sesgo (boosting) o se mejore la precisión (stacking) \cite{smolyakov}. 

\subsection{Combinando Métodos}
La combinación de métodos es el último paso en la estrategia de construcción de un sistema ensamblado de aprendizaje automatizado. La pregunta de que métodos combinar esta estrechamente relacionado con el tipo de juegos de datos y la solución que se busca alcanzar. Por ejemplo, alguno métodos de clasificación como los vectores de soporte solo devuelven valores discretos \cite{ensembleMachineLearning}. De tal manera el uso de dos métodos alternos en uno ensamblado estará determinado por la forma final en que se ensamblan y el algoritmo final utilizado para la decisión de predicción. Tanto Polikar \cite{ensembleMachineLearning} como Zhou \cite{ensembleMethods} citan como preferibles las metodologías de voto por mayoría, promedio, promedio ponderado, y ensamblaje infinito. Dzeroski y Zenko denotan que la mayoría de la investigación alrededor de métodos ensamblados se da con la generación de ensambles utilizando un único algoritmo de clasificación, como por ejemplo los árboles de decisión o el entrenamiento de redes neuronales \cite{DzeroskiZenko}. 

Smolyakov divide los métodos ensamblados en dos grandes clasificaciones \cite{smolyakov}:

\begin{itemize}
  \item \textbf{Métodos Ensamblados Secuenciales:} son aquellos donde los modelos bases de aprendizaje se generan de forma secuencial. La idea inicial es que se explota la dependencia entre dichos modelos base al momento de generarlos. Un buen ejemplo de modelos ensamblados secuenciales es \emph{AdaBoost}. El desempeño de predicción o la acotación del margen de error se optimiza al calibrar los regresores y/o clasificadores después de cada entrenamiento y previo al próximo. 
  \item \textbf{Métodos Ensamblados Paralelos:} son aquellos en los cuales los modelos bases se generar en forma paralela e independiente. Un buen ejemplo de modelos ensamblados paralelos es \emph{Random Forest}. La motivación de utilizar modelos ensamblados paralelos es maximizar la independencia entre los regresores y/o clasificadores que se optimizan entre si al promediar los resultados, reduciendo el margen de error. 
\end{itemize}

\subsection{Diversidad}
La diversidad de ensamblaje, o la diferencia entre diferentes métodos de aprendizaje, es un tema fundamental en el ensamblaje de métodos \cite{ensembleMethods}. Intuitivamente es fácil entender que para obtener una ventaja de la combinación, es necesario que los aprendizajes sean diferentes, de otra manera la ganancia en desempeño no seria marginalmente superior a los métodos por separado \cite{ensembleMethods}.

La mayoría de los métodos ensamblados utilizan solo un tipo de modelo base de algoritmo de aprendizaje para producir regresores o clasificadores homogéneos (del mismo tipo) conocidos como \textit{ensamblajes homogéneos} \cite{smolyakov}. También existen métodos que utilizan diferentes tipos de modelos bases como clasificadores y/o regresores. Estos modelos ensamblados se conocen como \textit{modelos heterogéneos}. Para poder ensamblar modelos más precisos que cualquiera de sus modelos base por si solos es necesario que los modelos bases sean precisos en primera instancia, y tan diversos como sea matemáticamente posible \cite{smolyakov}.

Para propósitos de este marco teórico revisaremos de forma breve los tres métodos más utilizados en la actualidad para el ensamblaje que son:
\begin{itemize}
  \item Bagging: cuando se busca reducir la varianza en los clasificadores
  \item Boosting: cuando se busca reducir el sesgo 
  \item Stacking: cuando se busca aumentar la predicción de los regresores
\end{itemize}

Dado que la hipótesis de trabajo del siguiente estudio utiliza el ensamblaje heterogéneo de modelos bases de regresión lineal y pronóstico de series de tiempo con ARIMA, haremos un alto para entrar con más detalle en la teoría y bondades de los modelos apilados (\emph{stacking}).

\subsection{Bagging}
La idea del \emph{bagging} esta estrechamente ligada al \emph{bootstrapping}, y determinada por la selección de múltiples muestras de datos generadas a través de \emph{bootstrapping}, utilizadas para alimentar clasificadores, sobre cuyos resultados el método ensamblado puede votar \cite{daume}. La palabra \emph{bagging} es la composición de \emph{bootstrap aggregation}. La etimología proviene de la metodología propia del método, que usa la agregación de múltiples muestras generadas de los datos disponibles (por ende, el \emph{bootstrapping}) para promediar múltiples estimados \cite{smolyakov}. 
Por ejemplo, se pudiera utilizar el \emph{bagging} para entrenar M árboles diferentes en diferentes juegos de datos seleccionados al azar con reemplazo para computar el ensamblado siguiente:  

\[ f(x) = \frac{1}{M} \sum_{m=1}^M f_m^{(x)} \]

\emph{Bagging} utiliza muestreo por \emph{bootstrap} para obtener juegos de datos para entrenar los modelos base. Para agregar los resultados de los modelos base, el \emph{bagging} utiliza dos maneras:
\begin{enumerate}
  \item Votación para clasificadores
  \item Promedios para regresión
\end{enumerate}

\subsection{Boosting}
El \emph{boosting} se refiere a una familia de técnicas de algoritmos que tienen la capacidad de convertir clasificadores (o regresores) débiles en entrenadores fuertes. El principio del \emph{boosting} es calzar una secuencia de clasificadores débiles - modelos que son escasamente mejores en la predicción que selección al azar, como por ejemplo pequeños árboles de decisión - a versiones ajustadas y sopesadas de los datos. Más peso se le otorga a los clasificadores que fueron mal clasificados en rondas anteriores \cite{smolyakov}. Daume describe el método como "\ldots La forma en la cual funciona el \emph{boosting} es que basado en un juego de datos y resultados pasados, va generando nuevas predicciones. Las predicciones con resultados aceptables se les pone menor peso y recursos, mientras que el algoritmo vuelve a iterar en aquellas predicciones con valores lejanos hasta que cobran fuerza \ldots" \cite{daume}. Esta técnica recibe el nombre de \textbf{AdaBoost}, del ingles \emph{adaptive boosting algotithm}. \textbf{AdaBoost} fue una de las primeras técnicas practicas en la ciencia de datos.

Los algoritmos de \emph{AdaBoost} comienzan ajustando los pesos del clasificador base \(y_1(x)\) a \(\frac{1}{N}\). Al comienzo todos los coeficientes de peso son los mismos. En rondas subsiguientes los coeficientes de peso se aumentan para aquellos puntos de datos que han sido mal clasificados y se reduce el peso de aquellos que han sido clasificados correctamente. Esta iteración es la que permite fortalecer los clasificadores débiles (a la vez fortaleciendo los débiles y debilitando los fuertes para contrastar mejor) \cite{smolyakov}. 

Existe una variable epsilon que representa el error ajustado de cada clasificador base. Hacia el final de las iteraciones del algoritmo los coeficientes ajustados alfa le otorgan mayor peso a los clasificadores con mayor precisión (la cual ha sido ajustada en \(n\) iteraciones). 

Una metodología derivada es el \emph{Boosting de Árboles Degradados}. Dicho método es una generalización del \emph{boosting} para funciones arbitrarias de pérdida \cite{smolyakov}. El mismo se puede utilizar tanto para problemas de clasificación como de regresión, y construye el modelo de forma secuencial:

\[ F_m(x) = F_{m-1}(x) + \gamma_m^{h_m(x)} \]

En cada nodo del árbol de decisión \(h_m(x)\) se elige para minimizar una función de pérdida \(L\) dado el modelo actual \(F_{m-1}(x)\):

\[ F_m(x) = F_{m-1}(x) + \argmin_h \sum_{i=1}^n L(y_i, F_{m-1}(x_i) + h(x_i) )\]

Los algoritmos para regresión y clasificación en este caso utilizan diferentes tipos de funciones de pérdida cuya explicación queda fuera del alcance de este marco teórico. 

\subsection{Stacking}
El \emph{stacking} - del inglés apilar - es una técnica de aprendizaje ensamblado que combina múltiples modelos de regresión o clasificación mediante un meta-regresor o un meta-clasificador. Los modelos base se entrenan en el juego de datos de entrenamiento, y luego el meta-modelo es entrenado en los resultados de los modelos base como variables \cite{smolyakov}. Los modelos base por lo general son diferentes algoritmos de aprendizaje automatizado, por lo que los modelos ensamblados por \emph{stacking} son usualmente heterogéneos. David Wolpert, del Centro de Estudio de Los Alamos, Nuevo México, escribió por primera vez sobre el método. Su propuesta era utilizar stacking generalizado como una manera de reducir el sesgo del entrenamiento de datos y el error de generalización. La tesis planteada es que el \emph{stacking} tiene un mejor margen de generalización ya que reduce el mismo al utilizar como fuente de datos de entrenamiento las predicciones (el cual denomina conjeturas en su artículo original) de un juego inicial de clasificadores \cite{wolpert}. Wolpert habla de un aprendizaje automatizado en dos espacios, uno inicial donde se toma como entradas los clasificadores base, y un segundo espacio, donde bautiza como \emph{generalizador} lo que la literatura actual denomina el meta-clasificador. La idea de generalización era la reducción del error del modelo aplicado a la vida real en solución de problemas. El concepto de sobreajuste (\textit{overfit}) no figura entonces pero lo que se buscaba era un método que generalizara mejor sobre datos de validación reduciendo el error generado por el sobreajuste de los modelos base sobre el juego de datos de entrenamiento. Dzeroski y Zenko han continuado los estudios de Wolpert y han presentado nuevos métodos de \emph{stacking}, incluyendo el uso de distribuciones de probabilidades y regresión lineal de múltiples respuestas como opciones que clasifican y predicen como mayor precisión \cite{DzeroskiZenko}. Ting y Witten definen la generalización por \emph{stacking} como una metodología general que utiliza un modelo de alto nivel que combina modelos inferiores para alcanzar mayores niveles de precisión en la predicción \cite{tingwitten}.

Dado que gran parte del trabajo de tesis doctoral involucra el uso de \emph{stacking}, el pseudo-código para el algoritmo se presenta a continuación. \\

\begin{lstlisting}
Input: data entrenamiento D = {xi,yi}, i=1...m
Output: clasificados ensamblado H
Paso 1: aprender de los clasificadores base
para t = 1 a T hacer:
	aprender h(t) basado en D
terminar bucle
Paso 2: construir un nuevo juego de datos para predicciones
para i = 1 a m hacer:
	D(h) = {xi', yi}, donde xi' = {h1(xi), ..., hT(xi)}
terminar bucle
Paso 3: aprender del meta-clasificador
aprender H basado en D(h)
retornar H
\end{lstlisting}

Entrando en mayor profundidad sobre la metodología, el \emph{stacking} se centra en la combinación de múltiples clasificadores generados por la utilización de diferentes algoritmos $L_1, \ldots, L_N$ en un juego de datos único S, el cual consiste de ejemplos $s_1 = (x_i, y_i)$, pares de vectores $(x_i)$ y sus clasificaciones $(y_i)$. En la primera fase, un juego de clasificadores bases $C_1, C_2, \ldots, C_N$ se generan, donde $C_i = L_i(S)$. En la segunda fase, un meta-clasificador se aprende de la combinación de salidas del clasificador base \cite{wolpert}

Para generar un juego de entrenamiento para el meta-clasificador, se puede aplicar un proceso de \emph{validación cruzada} o \emph{dejar-uno-fuera}. En caso de utilizar el proceso de dejar-uno-afuera, se aplica cada uno de los algoritmos base a todo el juego de datos menos un ejemplo para prueba: $\forall i = 1, \ldots, n : \forall k = 1, \ldots, N : C^{i}_{k} = L_k(S - S_i)$. Luego se utilizan los clasificadores aprendidos para generar predicciones para $s_i : \hat{y}^{k}_{i} = C^{i}_{k}(x_i)$. El juego de datos a meta-nivel consiste de ejemplos de la forma $((\hat{y}^{l}_{i}, \ldots, \hat{y}^{n}_{i}), y_i)$ donde los regresores o clasificadores son las predicciones de los regresores/clasificadores base y la clase es la clase correcta del ejemplo a mano \cite{DzeroskiZenko}.

La decisión de que meta-clasificador o meta-regresor utilizar es por el momento decisión del científico de datos en cada caso, y un tema que ha llevado a controversias en la comunidad de la ciencia estadística.  El método de stacking continúa su evolución como por ejemplo el uso de distribuciones de probabilidades. Ting y Witten continúan el trabajo de Wolpert concentrandosé en los que ellos llaman los dos factores cruciales de los métodos de \emph{stacking} generalizado: el tipo de generalizador más conveniente para derivar el modelo de nivel superior, y los tipos de atributos que debieran ser utilizados como variables de ingreso \cite{tingwitten}. Los autores introducen una metodología novel donde se ensamblan clasificadores cuyas predicciones son las distribuciones de probabilidad de los valores de las clases, en vez de los valores de las clases en si. Ende, los meta-atributos son probabilidades de cada una de los valores de clase que arroja cada uno de los clasificadores base. Los autores aducen que esto no solo les permite hacer predicciones, sino utilizar el intervalo de confidencia de los clasificadores base. 

Cada clasificador base predice una distribución de probabilidades para un juego de posibles valores de clase. La predicción de un clasificador base $C$ aplicada al ejemplo $x$ es una distribución de probabilidades a su vez:

\[ p^c(x) = (p^c(c_1 \mid x), (p^c(c_2 \mid x), \ldots, (p^c(c_m \mid x)) \]

donde ${c_{1}, c_{2}, \ldots, c_m}$ es el rango de posibles valores de la clase y $(p^c(c_i \mid x)$ denota la probabilidad de que dicho ejemplo $x$ pertenezca a la clase $c_i$ como lo estima (y predice) el clasificador $C$. La clase $c_j$ con la probabilidad más alta $p^C(c_j \mid x)$ se predice con el clasificador $C$. Los meta-atributos son las predicciones de probabilidades para cada clase posible según cada uno de los clasificadores base \cite{DzeroskiZenko}. 
