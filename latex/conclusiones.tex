\setcounter{chapter}{4}
\chapter{Conclusiones y Recomendaciones}
El siguiente trabajo de investigación nació de la observación generalizada entre los círculos contables de Colombia que la tasa de cambio TRM estaba relacionada de alguna forma a las altas y bajas del precio internacional del petroleo. Dicha inquietud se transformó en la piedra angular de nuestra hipótesis de trabajo y fue utilizada para diseñar un modelo predictivo de la TRM utilizando los principales rubros de exportación de Colombia como regresores y la variable independiente de la tasa de cambio en un modelo combinado, creado a través del aprendizaje automatizado. El resultado es un modelo ensamblado combinado parsimonioso y preciso.

\section{Conclusiones}
La investigación valida en cierta manera el uso de la Ciencia de Datos, y más profundamente del Aprendizaje Automatizado, dentro de la empresa moderna, donde el manejo científico de la información se vuelve una ventaja competitiva importante. Fuera del conocimiento profesional para aplicar las metodologías de entrenamiento y evaluación de modelos de aprendizaje automatizado, el costo para la empresa moderna es mínimo. Las herramientas \emph{Open Source} nunca fueron tan abundantes, y el poder de los computadores modernos hace que el tiempo y esfuerzo necesarios para programar y ejecutar programas y fuentes de datos inclusive copiosas sea relativamente barato y rápido.

Se cumple el adagio popular en la Ciencia de Datos que un 70\% del tiempo se destina en la recolección, limpieza y validación de las fuentes de datos. En el caso del trabajo de investigación doctoral el tiempo destinado al \emph{data wrangling} superó el 80\%. Una vez se contó con las fuentes de datos adecuadas, los cálculos matemáticos tardaron solo minutos en una estación de trabajo avanzada. Originalmente se planteó la necesidad de encontrar modelos predictivos con un índice de precisión superior al 95\% (entendiéndose esto como valores $p < 0.05$).Los modelos fabricados en base a metodologías de aprendizaje automatizado conllevan coeficientes de determinación superior al 98\% de precisión y valores $p < 0.01$. De tal forma cumplimos con los tres objetivos específicos del trabajo.

\begin{itemize}
    \item Identificamos en forma de un correlograma a través del uso de metodologías EDA (Explorative Data Analysis) los principales rubros de exportación y sus coeficientes de correlación con el precio de la TRM
    \item Cuantificamos y determinamos las mismas dentro de un modelo de predicción con valores inferiores al $p < 0.05$ originalmente establecido
    \item Determinamos que el mejor modelo es uno parsimonioso ensamblado resultante de combinar un aprendiz de regresión multivariable con un aprendiz ARIMA
\end{itemize}

Cada método de aprendizaje automatizado utilizado en el siguiente trabajo de investigación tiene sus bondades. Para discutir cada uno con total objetividad, haremos referencia a una sola tabla comparativa de valores de desempeño y precisión.

\begin{itemize}
    \item El modelo ARIMA tuvo resultados por encima de las expectativas del investigador, con un valor de error cuadrático bajo y un valor de coeficiente de determinación alto, ciertamente superior al método de regresión lineal multivariable. La fortaleza del pronóstico ARIMA se fundamente en lo completo y robusto del juego de datos utilizado. La serie de tiempo de la TRM es estudiada por todo el sector contable, económico y financiero de Colombia, por lo que no fue sorpresa que de todas las series de datos está fuera la más accesible de estudio. El comportamiento de la serie de datos TRM también tienen una tendencia secular y de estacionalidad muy marcadas que se ajusta al uso de metodologías como ARIMA. Dado el caso de no contar con otras metodologías o acceso a base de datos mayores para ampliar el rango de métodos potables, el uso de un aprendiz ARIMA puede solucionar el problema de pronosticar el valor futuro de la TRM sin necesidad de mayor complicación.
    \item El modelo de regresión lineal multivariable tuvo el desempeño menos preciso de los tres métodos estudiados. El valor del error cuadrático fue el mayor de los tres (aunque no necesariamente se puede decir que fue alto) y el coeficiente de determinación fue el menor de los tres (aunque fue alto estadísticamente hablando). El uso de los rubros de exportación como regresores se justifica con el calce ajustado del modelo, por lo que se considera un modelo robusto y parsimonioso. Sin embargo es un modelo más difícil de aplicar sin conocimientos de programación de métodos de aprendizaje automatizado y no rindió mejores pronósticos que el uso más sencillo de ARIMA.
    \item Correspondiendo con la literatura y los trabajos de autores como Daroczi, Leek, Peng y Tattar, el modelo ensamblado tuvo los mejores niveles de desempeño y precisión con el error cuadrático más bajo y el coeficiente de determinación más alto. La utilización de los dos métodos iniciales como entradas para un aprendiz ensamblado genera un método más robusto que se nutre de entradas pre-procesadas por los aprendices que las componen. Habiendo dicho esto, el desempeño obtenido por el método ensamblado no se puede considerar sino marginal en comparación con los aprendices que lo alimentan. La diferencia del error cuadrático es considerable si se mide contra el aprendiz de regresión lineal multivariable, pero poco notable contra el aprendiz ARIMA. De la misma forma, el valor del coeficiente de determinación su superior por menos de 0.026 contra el aprendiz de regresión lineal multivariable, pero nuevamente imperceptible versus el aprendiz ARIMA.
\end{itemize}

Dado la estrecha diferencia entre la precisión del modelo ARIMA versus el modelo ensamblado, es comprensible cuestionar la complejidad adicional requerida en contraposición al rendimiento marginal. La utilización de la TRM en contratos de futuros o \emph{forwards} puede justificar la complejidad adicional de implementar un algoritmo compuesto. Para funciones de análisis de costos el \emph{overhead} adicional de lidiar con un modelo ensamblado puede no hacer diferencias en el costeo final, sobre todo en cifras con redondeos a 2 decimales.

Para la organización moderna y de amplio alcance la complejidad adicional de la utilización de modelos ensamblados puede verse recompensada con el tiempo. El mayor nivel de precisión siempre redundará en mejores márgenes de utilidad y ganancias de productividad. En un ambiente dinámico y de bajo margen de utilidad como lo es el negocio de corretaje bursátil dicha precisión puede ser la diferencia entre la viabilidad de operación o no. Para reportes ad-hoc, análisis de factibilidad, o toma rápida de decisiones, el uso de modelos ensamblados puede no ser la mejor respuesta. El trabajo de investigación doctoral llegó a un modelo parsimonioso y preciso con el uso del modelo ARIMA, el más sencillo de los tres de aplicar y entender. En el caso de tener que afrontar pronósticos de mediana exactitud, un modelo simple y rápido de aplicar puede satisfacer a la organización mejor que uno de mayor precisión pero intensivo en el uso de recursos y bases de datos extensas y validadas.

\section{Recomendaciones}
El trabajo de investigación pone en evidencia tres puntos importantes que se vuelven recomendaciones tanto para el ámbito académico como para el profesional.

\begin{enumerate}
    \item \textbf{La data es el punto de partida:} todo trabajo de ciencia de datos parte del enfoque científico de la data, lo que obliga a utilizar juegos de datos validados, estructurados, completos y estadísticamente válidos. Aquello que en la organización moderna se considera data válida puede no serlo desde el enfoque científico o llevar a bases de datos incompletas. El trabajo de investigación se apoyó en base de datos comerciales de la casa \emph{Quandl} que demostraron tener niveles mayores a lo esperado de inconsistencias. A pesar de todo el tiempo destinado por la academia de sistemas y los estudiosos de las estructuras de datos, seguimos teniendo mejores estructuras de datos que consistencia y calidad de datos. Por ejemplo, las series de tiempo de la tasa de cambio TRM tienen una estructura ordenada y rigurosa, pero incompleta inclusive para ser considerada series de tiempo con $n$ frecuencia establecida. Lo que para el ingeniero en sistemas puede ser perfecto y normalizado, no lo será para el científico de datos. La normalización y validación de los datos debe ser el primer punto de cuidado en la creación de instrumentación adecuada. Los datos se encontraran en cantidades copiosas pero no necesariamente en calidad.
    \item \textbf{El número de metodologías de aprendizaje automatizado excede el estudio potencial del número de datos:} Una metodología tan sencilla como el estudio de las series de tiempo puede complicarse rápidamente con temas matemáticos de nivel doctoral que extraigan más información de los datos en si que la existencia de preguntas. La aplicación tecnológica de los métodos de aprendizaje automatizado arroja resultados muy precisos con necesidades muy bajas de sofisticación. La bibliografía y los investigadores están ahondando en metodologías cada vez más complejas - como lo son las redes neuronales radiales y por cuantiles - sin que la precisión de los resultados sea mayor en términos prácticos a otras metodologías más sencillas. Un juego sencillo de datos, una vez puesto bajo el escrutinio del EDA, puede abrir la clave de un sinnúmero de investigaciones y aplicaciones. Es preferible extenderse con más profundidad en un juego de datos extenso pero reducido en variables con un portafolio reducido de métodos, a expandirse muy rápidamente en la cantidad de variables a estudiar y la metodología aplicada. Sin demeritar la investigación teórica original, la investigación aplicada arrojará mayor resultados prácticos a los problemas de la contabilidad y finanzas de la organización moderna.
    \item \textbf{Un modelo predictivo no es un modelo de producción:} La consecución de un modelo predictivo, aún uno sencillo y parsimonioso, no es un modelo de producción que se puede trasladar al uso común y corriente dentro de la organización. El modelo ensamblado de predicción de la TRM vive dentro de un entorno específico y bajo instrumentación limitada (llamase un entorno de programación R con estructuras de datos del tipo \emph{data frame}). Dicho entorno no puede utilizarse en la organización moderna como reporte en una base de datos Oracle o una macro EXCEL. El diseño de modelos predictivos utilizando aprendizaje automatizado aún convive como un entorno aislado cuya integración al resto del sistema de la organización queda como tema pendiente en la pequeña y mediana empresa, y recien se comienza a integrar en los grandes ambientes corporativos con herramientas como Watson de IBM y Azure de Microsoft.
\end{enumerate}

\section{Sugerencias para Futuras Investigaciones}
A lo largo del trabajo de investigación surgieron dudas o preguntas que no pudieron ser contestadas, ya sea por encontrarse fuera del enfoque o alcance de la investigación o porque mutaban en nuevas líneas de investigación. Las mismas se detallan a continuación como propuestas de futuras investigaciones doctorales o post-doctorales.

\begin{itemize}
    \item \emph{El Entrenamiento de Series de Tiempo:} Las series de tiempo - por lo general no-estacionarias - conllevan el problema inherente de autocorrelación lo que complica su división en juegos de entrenamiento y evaluación. La mayoría de los autores y librerías disponibles en R evitan el problema utilizando el total de los datos para entrenar el modelo y un juego reducido sin reemplazo para la validación cruzada. Esto representa un problema para la metodología de modelos ensamblados. El aprendiz del modelo ensamblado debe nutrirse con los egresos de los juegos de test de los aprendices que lo conforman. Dentro del trabajo doctoral circunvalamos el problema generando un juego adicional de test del aprendiz ARIMA con reemplazo, lo que funcionó muy bien, pero fue un trabajo manual y no uno automatizado como lo hace la biblioteca CARET con los juegos de datos para métodos generales de regresión. Es de estimar que solucionar dicho problema ayudaría a muchos investigadores de series de datos a automatizar el flujo de trabajo cuando se entrenan series de datos con altos niveles de autocorrelación. \item \emph{Métodos Adicionales de Aprendizaje Automatizado:} El trabajo de investigación utilizó solo tres métodos de aprendizaje automatizado (ARIMA, regresión multivariable, y ensamblado). Pero existen decenas de otros métodos que pudieran mejorar aun más el nivel de precisión del modelo predictivo, como las Series Rápidas de Fourier, Arboles Aleatorios, Redes Neuronales, Deep Learning, etc.
    \item \emph{Alimentación Primaria del Modelo Predictivo:} El modelo predictivo utiliza como entradas regresores en la forma de rubros de exportación. ¿Pero como estimamos el valor futuros de los regresores para mejorar el horizonte de predicción del modelo? ¿Es posible retroalimentar regresores con el valor futuro de la variable dependiente, o utilizar algún proceso de \emph{bootstrap} que genere modelos predictivos iniciales de los regresores, los utilice para la extensión de los juegos de datos en híbridos (series de datos con datos históricos y sintéticos) y luego se entrene con miras a extender el rango de la predicción?
\end{itemize}
